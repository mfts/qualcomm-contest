{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQsuX0CsGQiq"
   },
   "source": [
    "# Space Invaders\n",
    "\n",
    "# Weights & Biases x Qualcomm - SpaceInvaders Challenge\n",
    "\n",
    "This notebook contains code for loading models from a file saved in a wandb run, and evaluating the model.\n",
    "\n",
    "For more details on the SpaceInvaders challenge, please visit the [competition website](https://app.wandb.ai/wandb/spaceinvaders-challenge/benchmark/).\n",
    "\n",
    "![](https://thumbs.gfycat.com/CookedFriendlyAntarcticfurseal-size_restricted.gif)\n",
    "\n",
    "## Running this notebook\n",
    "1. Click \"Open in playground\" to create a copy of this notebook for yourself.\n",
    "2. Save a copy in Google Drive for yourself.\n",
    "3. To enable a GPU, please click Edit > Notebook Settings. Change the \"hardware accelerator\" to GPU.\n",
    "4. Step through each section, pressing play on the code blocks to run the cells.\n",
    "5. Add your own model code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LlzpxEOsIePf"
   },
   "source": [
    "## Load the model\n",
    "\n",
    "Please replace the model file (`model.h5`) and run_path (`username/project_name/run_name`) with your submissions model file and run_path respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DrVri-RnXD2B"
   },
   "outputs": [],
   "source": [
    "# restore a model file from a specific run by user \"lavanyashukla\" in project \"qualcomm\" from run \"mnswzdre\"\n",
    "fname = \"model.h5\"\n",
    "run_path=\"lavanyashukla/qualcomm/b0qh2jcw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkNyJEmQRWOu"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade wandb -qq\n",
    "# import wandb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "maz6vvi5HlAp",
    "outputId": "d451d63b-8fee-42ad-ace3-d35a732a1f41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# restore model\n",
    "api = wandb.Api()\n",
    "run = api.run(run_path)\n",
    "local_path = None\n",
    "with run.file(fname).download(replace=True) as f:\n",
    "  local_path = f.name\n",
    "agent = load_model(local_path)\n",
    "agent.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJ8AMc_zWCnS"
   },
   "source": [
    "## Setup and Preproceesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yvHkMNUGGKCb"
   },
   "outputs": [],
   "source": [
    "!pip install gym pyvirtualdisplay -qq\n",
    "!apt-get install -y xvfb python-opengl ffmpeg -qq\n",
    "!pip install xdpyinfo -qq\n",
    "\n",
    "!apt-get update -qq\n",
    "!apt-get install cmake -qq\n",
    "!pip install --upgrade setuptools -qq\n",
    "!pip install ez_setup -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDpK4FdgHHsR"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import Monitor\n",
    "gymlogger.set_level(30)\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import glob\n",
    "import io\n",
    "import os\n",
    "import cv2\n",
    "import base64\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import keras\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "from pyvirtualdisplay import Display\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HN-f-hFHMeQ"
   },
   "outputs": [],
   "source": [
    "color = np.array([210, 164, 74]).mean()\n",
    "\n",
    "def preprocess_frame(obs):\n",
    "    img = obs[25:201:2, ::2]\n",
    "\n",
    "    # Convert to greyscale\n",
    "    img = img.mean(axis=2)\n",
    "\n",
    "    # Improve contrast\n",
    "    img[img==color] = 0\n",
    "\n",
    "    # Normalzie image\n",
    "    img = (img - 128) / 128 - 1\n",
    "\n",
    "    # Reshape to 80*80*1\n",
    "    img = img.reshape(88, 80)\n",
    "\n",
    "    return img "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hwt-wy0NWHuH"
   },
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fIZiiAW6HTil"
   },
   "outputs": [],
   "source": [
    "# **** Caution: Do not modify this cell ****\n",
    "# initialize total reward across episodes\n",
    "cumulative_reward = 0\n",
    "episode = 0\n",
    "\n",
    "def evaluate(episodic_reward, reset=False):\n",
    "  '''\n",
    "  Takes in the reward for an episode, calculates the cumulative_avg_reward\n",
    "    and logs it in wandb. If episode > 100, stops logging scores to wandb.\n",
    "    Called after playing each episode. See example below.\n",
    "\n",
    "  Arguments:\n",
    "    episodic_reward - reward received after playing current episode\n",
    "  '''\n",
    "  global episode\n",
    "  global cumulative_reward\n",
    "  if reset:\n",
    "    cumulative_reward = 0\n",
    "    episode = 0\n",
    "    \n",
    "  episode += 1\n",
    "  print(\"Episode: %d\"%(episode))\n",
    "\n",
    "  # your models will be evaluated on 100-episode average reward\n",
    "  # therefore, we stop logging after 100 episodes\n",
    "  if (episode > 100):\n",
    "    print(\"Scores from episodes > 100 won't be logged in wandb.\")\n",
    "    return\n",
    "\n",
    "  # log total reward received in this episode to wandb\n",
    "  wandb.log({'episodic_reward': episodic_reward})\n",
    "\n",
    "  # add reward from this episode to cumulative_reward\n",
    "  cumulative_reward += episodic_reward\n",
    "\n",
    "  # calculate the cumulative_avg_reward\n",
    "  # this is the metric your models will be evaluated on\n",
    "  cumulative_avg_reward = cumulative_reward/episode\n",
    "\n",
    "  # log cumulative_avg_reward over all episodes played so far\n",
    "  wandb.log({'cumulative_avg_reward': cumulative_avg_reward})\n",
    "\n",
    "  return cumulative_avg_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WDCVUIhxWL-n"
   },
   "source": [
    "## Play the game for 100 episodes, log cumulative average reward, for 5 different values of seed\n",
    "\n",
    "Please adjust this as needed to work with your model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHyYmf2AHWBn"
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "cumulative_avg_rewards = []\n",
    "for seed_ in [10, 50, 100, 200, 500]:\n",
    "  seed(seed_)\n",
    "  set_random_seed(seed_)\n",
    "  print(\"Seed: \",seed_)\n",
    "  episode = 0\n",
    "\n",
    "  # initialize environment\n",
    "  env = gym.make('SpaceInvaders-v0')\n",
    "  state_size = env.observation_space.shape[0]\n",
    "  action_size = env.action_space.n\n",
    "  print(\"Actions available(%d): %r\"%(env.action_space.n, env.env.get_action_meanings()))\n",
    "\n",
    "  # initialize a new wandb run\n",
    "  wandb.init(project=\"qualcomm-evaluation\")\n",
    "\n",
    "  # define hyperparameters\n",
    "  wandb.config.episodes = 100\n",
    "  wandb.config.runpath = run_path\n",
    "\n",
    "  # record gameplay video\n",
    "  display = Display(visible=0, size=(1400, 900))\n",
    "  display.start()\n",
    "\n",
    "  # run for 100 episodes\n",
    "  # Note: Please adjust this as needed to work with your model architecture.\n",
    "  # Make sure you still call evaluate() with the reward received in each episode\n",
    "  for i in range(wandb.config.episodes):\n",
    "    # Set reward received in this episode = 0 at the start of the episode\n",
    "    episodic_reward = 0\n",
    "    reset = False\n",
    "\n",
    "    # record a video of the game using wrapper\n",
    "    env = gym.wrappers.Monitor(env, './video', force=True)\n",
    "    \n",
    "    # play a random game\n",
    "    state = env.reset()\n",
    "    state = preprocess_frame(state)\n",
    "\n",
    "    done = False\n",
    "    action_count = 0\n",
    "    while not done:\n",
    "      # get prediction for next action from model\n",
    "      actions = agent.predict(state)\n",
    "      action = np.argmax(actions, axis=-1)\n",
    "      action = np.argmax(action)\n",
    "\n",
    "      # perform the action and fetch next state, reward\n",
    "      next_state, reward, done, _ = env.step(action)\n",
    "      next_state = preprocess_frame(next_state)\n",
    "      state = next_state\n",
    "\n",
    "      action_count += 1\n",
    "      if(action_count == 50):\n",
    "        done = True\n",
    "        break\n",
    "\n",
    "      episodic_reward += reward\n",
    "    \n",
    "    # call evaluation function - takes in reward received after playing an episode\n",
    "    # calculates the cumulative_avg_reward over 100 episodes & logs it in wandb\n",
    "    if(i==0):\n",
    "      reset = True\n",
    "\n",
    "    cumulative_avg_reward = evaluate(episodic_reward, reset)\n",
    "\n",
    "    # your models will be evaluated on 100-episode average reward\n",
    "    # therefore, we stop logging after 100 episodes\n",
    "    if (i >= 99):\n",
    "      cumulative_avg_rewards.append(cumulative_avg_reward)\n",
    "      break\n",
    "\n",
    "    record_video = False\n",
    "    env.close() \n",
    "\n",
    "    # render gameplay video\n",
    "    if (i %50 == 0):\n",
    "      mp4list = glob.glob('video/*.mp4')\n",
    "      if len(mp4list) > 0:\n",
    "        print(len(mp4list))\n",
    "        mp4 = mp4list[-1]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "\n",
    "        # log gameplay video in wandb\n",
    "        wandb.log({\"gameplays\": wandb.Video(mp4, fps=4, format=\"gif\")})\n",
    "\n",
    "        # display gameplay video\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"\" autoplay \n",
    "                    loop controls style=\"height: 400px;\">\n",
    "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                </video>'''.format(encoded.decode('ascii'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KV-irjWcYDAE"
   },
   "source": [
    "# Final score\n",
    "The final score is evaluated as the cumulative_avg_reward, averaged across 5 seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pKiJcC0WJ4W-"
   },
   "outputs": [],
   "source": [
    "print(\"Final score: \", np.mean(cumulative_avg_rewards))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SpaceInvaders Evaluation Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
